{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2026-02-08T14:52:13.226589700Z",
     "start_time": "2026-02-08T14:52:13.126519600Z"
    }
   },
   "source": [
    ""
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-08T14:52:17.601147900Z",
     "start_time": "2026-02-08T14:52:13.236020600Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import os\n",
    "from itertools import combinations, product\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "\n",
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots\n",
    "import plotly.express.colors as px_colors\n",
    "import plotly.io as pio\n",
    "from scipy.spatial.distance import squareform\n",
    "\n",
    "import SpAM_Simulations.metrics as metrics\n",
    "from SpAM_Simulations.simulation import load_latest_simulation, create_simulation\n",
    "\n",
    "pio.renderers.default = 'browser'"
   ],
   "id": "db5cd83d5162a54a",
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Load or Make Simulation",
   "id": "569fe8f490f84a2d"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-08T14:53:22.319044200Z",
     "start_time": "2026-02-08T14:52:18.104482Z"
    }
   },
   "cell_type": "code",
   "source": [
    "try:\n",
    "    sim = load_latest_simulation(os.getcwd())\n",
    "except FileNotFoundError:\n",
    "    # sim = create_simulation(\n",
    "    #     n_images = 50,\n",
    "    #     n_dims = 5,\n",
    "    #     num_subjects = [20, 30],\n",
    "    #     trials_per_subject = [8, 10],\n",
    "    #     images_per_trial = [16, 20],\n",
    "    #     subjects_noise_scale = [0.15, 0.3],\n",
    "    #     subjects_noise_df = [1, 3],\n",
    "    #     reps = 3,\n",
    "    #     seed = 42,\n",
    "    #     verbose = True,\n",
    "    # )\n",
    "    sim = create_simulation(\n",
    "        n_images = 754,\n",
    "        n_dims = 10,\n",
    "        num_subjects = [20, 30, 50, 100, 200],\n",
    "        trials_per_subject = [8, 10, 15, 20],\n",
    "        images_per_trial = [16, 20, 25],\n",
    "        subjects_noise_scale = [0.15, 0.3, 0.5],\n",
    "        subjects_noise_df = [1, 3, 5],\n",
    "        reps = 5,\n",
    "        seed = 42,\n",
    "        verbose = True,\n",
    "    )"
   ],
   "id": "1565a6331b861acc",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Evaluate Simulation\n",
    "### Coverage"
   ],
   "id": "32e6ca94afcd65b1"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "start_time": "2026-02-08T14:53:24.336390600Z"
    }
   },
   "cell_type": "code",
   "source": [
    "coverage = []\n",
    "for param in sim._results.keys():\n",
    "    for rep, result in enumerate(sim._results[param]):\n",
    "        coverage.append(pd.Series(metrics.coverage(result)).rename((*param, rep)))\n",
    "del param, rep, result\n",
    "\n",
    "coverage = pd.concat(coverage, axis=1).T\n",
    "coverage.index.names = [\n",
    "    'n_subjects', 'trials_per_subject', 'images_per_trial', 'subjects_noise_scale', 'subjects_noise_df', 'rep',\n",
    "]\n",
    "coverage[\"is_connected\"] = coverage[\"num_connected_components\"] == 1.0\n",
    "\n",
    "# coverage scores are not affected by subject noise, so we average across those parameters\n",
    "coverage_summary = (\n",
    "    coverage.groupby([\"n_subjects\", \"trials_per_subject\", \"images_per_trial\"])\n",
    "    .agg(\n",
    "        num_reps = (\"average_obs_count\", \"size\"),\n",
    "        obs_count_mean = (\"average_obs_count\", \"mean\"),\n",
    "        obs_count_sem = (\"average_obs_count\", \"sem\"),\n",
    "        percent_coverage_mean = (\"coverage\", \"mean\"),\n",
    "        percent_coverage_sem = (\"coverage\", \"sem\"),\n",
    "        percent_coverage5x_mean = (\"coverage@5\", \"mean\"),\n",
    "        percent_coverage5x_sem = (\"coverage@5\", \"sem\"),\n",
    "        p_is_connected_mean = (\"is_connected\", \"mean\"),\n",
    "        p_is_connected_sem = (\"is_connected\", \"sem\"),\n",
    "    )\n",
    "    .sort_index()\n",
    "    .reset_index()\n",
    ")"
   ],
   "id": "3bbeec254418e12",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "ROW_TITLES = {\n",
    "    \"# of Ratings\": \"obs_count\", \"% COVERAGE\": \"percent_coverage\", \"% COVERAGE@5\": \"percent_coverage5x\"\n",
    "}\n",
    "COL_TITLES = {k: f\"{k} Images per Trial\" for k in coverage_summary[\"images_per_trial\"].unique()}\n",
    "coverage_fig = make_subplots(\n",
    "    rows=len(ROW_TITLES), cols=len(COL_TITLES),\n",
    "    column_titles=list(COL_TITLES.values()),\n",
    "    shared_xaxes=True, shared_yaxes=True,\n",
    "    x_title=\"Number of Subjects\",\n",
    "    vertical_spacing=0.05, horizontal_spacing=0.025,\n",
    ")\n",
    "for c, (images_per_trial, col_title) in enumerate(COL_TITLES.items()):\n",
    "    for r, (row_title, prefix) in enumerate(ROW_TITLES.items()):\n",
    "        for i, tr in enumerate(coverage_summary[\"trials_per_subject\"].unique()):\n",
    "            color = px_colors.qualitative.Plotly[i]\n",
    "            df = coverage_summary.loc[\n",
    "                (coverage_summary[\"trials_per_subject\"] == tr) & (coverage_summary[\"images_per_trial\"] == images_per_trial),\n",
    "            ]\n",
    "            coverage_fig.add_trace(\n",
    "                row=r + 1, col=c + 1, trace=go.Scatter(\n",
    "                    x=df[\"n_subjects\"],\n",
    "                    y=df[f\"{prefix}_mean\"],\n",
    "                    error_y=dict(type=\"data\", array=df[f\"{prefix}_sem\"], visible=True),\n",
    "                    name=str(tr), legendgroup=str(tr), showlegend=c == 0 and r == 0,\n",
    "                    mode=\"lines+markers\", line=dict(color=color),\n",
    "                )\n",
    "            )\n",
    "        if c == 0:\n",
    "            coverage_fig.update_yaxes(\n",
    "                row=r + 1, col=c + 1,\n",
    "                title=dict(text=row_title, font=dict(size=14, color='black'))\n",
    "            )\n",
    "del c, r, i, images_per_trial, col_title, row_title, prefix, tr, color, df\n",
    "\n",
    "coverage_fig.update_layout(\n",
    "    height=650, width=1500,\n",
    "    title=dict(\n",
    "        text=\"Coverage by Experimental Configuration\", font=dict(size=20, color='black')\n",
    "    ),\n",
    "    legend=dict(\n",
    "        title=dict(text=\"Trials per Subject\"),\n",
    "        orientation=\"h\",\n",
    "        x=1.0, xanchor=\"right\", xref=\"paper\",\n",
    "        y=1.075, yanchor=\"bottom\", yref=\"paper\",\n",
    "    ),\n",
    ")\n",
    "coverage_fig.show()"
   ],
   "id": "9f34d35492d4131e",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Connected Components\n",
    "The `MDS` algorithm requires a fully connected graph, so we first want to check the probability of getting a fully connected graph for various experimental configurations."
   ],
   "id": "d2d6199976067bf9"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "COL_TITLES = {k: f\"{k} Images per Trial\" for k in coverage_summary[\"images_per_trial\"].unique()}\n",
    "PREFIX = \"p_is_connected\"\n",
    "cc_fig = make_subplots(\n",
    "    rows=1, cols=len(COL_TITLES),\n",
    "    column_titles=list(COL_TITLES.values()),\n",
    "    shared_xaxes=True, shared_yaxes=True,\n",
    "    x_title=\"Number of Subjects\",\n",
    "    vertical_spacing=0.05, horizontal_spacing=0.025,\n",
    ")\n",
    "for c, (images_per_trial, col_title) in enumerate(COL_TITLES.items()):\n",
    "    for i, tr in enumerate(coverage_summary[\"trials_per_subject\"].unique()):\n",
    "        color = px_colors.qualitative.Plotly[i]\n",
    "        df = coverage_summary.loc[\n",
    "            (coverage_summary[\"trials_per_subject\"] == tr) & (coverage_summary[\"images_per_trial\"] == images_per_trial),\n",
    "        ]\n",
    "        cc_fig.add_trace(\n",
    "            row=1, col=c + 1, trace=go.Scatter(\n",
    "                x=df[\"n_subjects\"],\n",
    "                y=df[f\"{PREFIX}_mean\"],\n",
    "                error_y=dict(type=\"data\", array=df[f\"{PREFIX}_sem\"], visible=True),\n",
    "                name=str(tr), legendgroup=str(tr), showlegend=c == 0,\n",
    "                mode=\"lines+markers\", line=dict(color=color),\n",
    "            )\n",
    "        )\n",
    "    if c == 0:\n",
    "        cc_fig.update_yaxes(\n",
    "            row=1, col=c + 1,\n",
    "            title=dict(text=\"P[Fully Connected]\", font=dict(size=14, color='black'))\n",
    "        )\n",
    "del c, i, images_per_trial, col_title, tr, color, df\n",
    "\n",
    "cc_fig.update_layout(\n",
    "    height=350, width=800,\n",
    "    title=dict(\n",
    "        text=\"Probability of Full Connectivity by Experimental Configuration\", font=dict(size=20, color='black')\n",
    "    ),\n",
    "    legend=dict(\n",
    "        title=dict(text=\"Trials per Subject\"),\n",
    "        orientation=\"h\",\n",
    "        x=1.0, xanchor=\"right\", xref=\"paper\",\n",
    "        y=1.075, yanchor=\"bottom\", yref=\"paper\",\n",
    "    ),\n",
    ")\n",
    "cc_fig.show()"
   ],
   "id": "402de0f68013cab1",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Stability\n",
    "We check the Spearman (rank) correlation between different iterations of the same experimental configuration to see how stable the results are."
   ],
   "id": "f8550503d991ccc3"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "correlations = dict()\n",
    "for param in sim._results.keys():\n",
    "    corrs = []\n",
    "    for res1, res2 in combinations(sim._results[param], 2):\n",
    "        try:\n",
    "            corr = metrics.spearman_correlation(res1, res2)\n",
    "            corrs.append(corr)\n",
    "        except ValueError:\n",
    "            # if we don't have mutual observations we can't compute a correlation, so we skip those cases\n",
    "            pass\n",
    "    corrs = pd.Series(corrs)\n",
    "    mean, sem = corrs.mean(), corrs.sem()\n",
    "    correlations[param] = pd.Series({\"r_mean\": mean, \"r_sem\": sem})\n",
    "del param, corrs, res1, res2, corr, mean, sem\n",
    "\n",
    "correlations = pd.DataFrame(correlations).T\n",
    "correlations.index.names = ['n_subjects', 'trials_per_subject', 'images_per_trial', 'subjects_noise_scale', 'subjects_noise_df']\n",
    "correlations"
   ],
   "id": "ee80dbfedeb78b85",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "ROW_TITLES = {tr: f\"{tr} Trials per Subject\" for tr in coverage_summary[\"trials_per_subject\"].unique()}\n",
    "COL_TITLES = {k: f\"{k} Images per Trial\" for k in coverage_summary[\"images_per_trial\"].unique()}\n",
    "corr_fig = make_subplots(\n",
    "    rows=len(ROW_TITLES), cols=len(COL_TITLES),\n",
    "    column_titles=list(COL_TITLES.values()),\n",
    "    shared_xaxes=True, shared_yaxes=True,\n",
    "    x_title=\"Number of Subjects\",\n",
    "    vertical_spacing=0.05, horizontal_spacing=0.025,\n",
    ")\n",
    "for c, (images_per_trial, col_title) in enumerate(COL_TITLES.items()):\n",
    "    for r, (trials_per_subject, row_title) in enumerate(ROW_TITLES.items()):\n",
    "        subset = correlations.loc[\n",
    "            (correlations.index.get_level_values(\"images_per_trial\") == images_per_trial) &\n",
    "            (correlations.index.get_level_values(\"trials_per_subject\") == trials_per_subject)\n",
    "        ]\n",
    "        noise_scales = subset.index.get_level_values(\"subjects_noise_scale\").unique()\n",
    "        noise_dfs = subset.index.get_level_values(\"subjects_noise_df\").unique()\n",
    "        for i, (noise_scale, noise_df) in enumerate(product(noise_scales, noise_dfs)):\n",
    "            name = f\"Scale={noise_scale}<br>DFs={noise_df}\"\n",
    "            color = px_colors.qualitative.Plotly[i]\n",
    "            df = subset.loc[\n",
    "                (subset.index.get_level_values(\"subjects_noise_scale\") == noise_scale) &\n",
    "                (subset.index.get_level_values(\"subjects_noise_df\") == noise_df)\n",
    "            ]\n",
    "            corr_fig.add_trace(\n",
    "                row=r + 1, col=c + 1, trace=go.Scatter(\n",
    "                    x=df.index.get_level_values(\"n_subjects\"),\n",
    "                    y=df[\"r_mean\"],\n",
    "                    error_y=dict(type=\"data\", array=df[\"r_sem\"], visible=True),\n",
    "                    name=name, legendgroup=name, showlegend=c == 0 and r == 0,\n",
    "                    mode=\"lines+markers\", line=dict(color=color),\n",
    "                )\n",
    "            )\n",
    "        if c == 0:\n",
    "            corr_fig.update_yaxes(\n",
    "                row=r + 1, col=c + 1,\n",
    "                title=dict(text=row_title, font=dict(size=10, color='black'))\n",
    "            )\n",
    "del c, r, i, images_per_trial, col_title, trials_per_subject, row_title, noise_scale, noise_df, name, color, df\n",
    "\n",
    "corr_fig.update_layout(\n",
    "    height=650, width=1500,\n",
    "    title=dict(\n",
    "        text=\"Stability (Spearman Correlation) by Experimental Configuration\",\n",
    "        font=dict(size=20, color='black')\n",
    "    ),\n",
    "    legend=dict(\n",
    "        title=dict(text=\"Subject Noise Parameters\"),\n",
    "    ),\n",
    ")\n",
    "corr_fig.show()"
   ],
   "id": "78639d58e332551",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-07T03:39:18.786377700Z",
     "start_time": "2026-02-07T03:39:18.729349900Z"
    }
   },
   "cell_type": "markdown",
   "source": [
    "## Run MDS\n",
    "In the real world, we don't know the true dimensionality of the data (like here, `D=5 or 10`). Instead, we run the MDS algorithm on the same distance matrix with increasing target-dimensionalities (`ndim=2, 3, ..., 10`)."
   ],
   "id": "bef45a0a5fbdd90a"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from SpAM_Simulations.multi_dimensional_scaling import run_mds\n",
    "\n",
    "#\n",
    "# res = list(sim._results.values())[0][0]\n",
    "# run_mds(res.distances, res.num_obs, 3, True)"
   ],
   "id": "bfd412f34a466e5",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "GT_DIMS = sim.gt_embeddings.shape[1]\n",
    "mds_inputs = dict()\n",
    "for i in range(2, GT_DIMS + 1):\n",
    "    for param in sim._results.keys():\n",
    "        for rep, result in enumerate(sim._results[param]):\n",
    "            key = tuple({**(param._asdict()), \"rep\": rep, \"ndim\": i}.items())\n",
    "            mds_inputs[key] = result\n",
    "\n",
    "mds_results = dict()\n",
    "for exp_param, exp_result in tqdm(mds_inputs.items(), desc=\"Running MDS\"):\n",
    "    try:\n",
    "        mds_result = run_mds(\n",
    "            dists=exp_result.distances,\n",
    "            weights=exp_result.num_obs,\n",
    "            ndim=exp_param[-1][1],\n",
    "            verbose=False,\n",
    "        )\n",
    "        mds_results[exp_param] = mds_result\n",
    "    except Exception as e:\n",
    "        mds_results[exp_param] = e"
   ],
   "id": "357d2b975b264094",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "id": "b084a60a40abf62e",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Percent Failures\n",
    "We want to check the percentage of MDS runs that failed for each experimental configuration and target dimensionality.<br>\n",
    "We checked the number of connected components before, but here we check for other causes as well, for example:\n",
    "- a RuntimeError with the words \"connected component\" indicates that there were more than 1 CC.\n",
    "- a RuntimeError with the words \"max_iter\" indicates that the MDS algorithm failed to converge within the maximum number of iterations."
   ],
   "id": "c3299e75914f37a8"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "id": "ca39ee8067a7e4e8",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Scree Plot\n",
    "We plot the **Scree Plot** showing Stress vs Dimensionality, and look for the \"elbow\" in the plot to determine the optimal dimensionality.<br>\n",
    "We should see if this is stable across iterations of the same experimental configuration."
   ],
   "id": "ce5089ee368e62c2"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "id": "a55751a19ceb8f93",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-07T05:54:07.010742800Z",
     "start_time": "2026-02-07T05:54:06.968469900Z"
    }
   },
   "cell_type": "markdown",
   "source": [
    "## Evaluate Embeddings\n",
    "### Stability\n",
    "We want to check how \"stable\" our embeddings are across different iterations of the same experimental configuration. To do this, we calculate the Spearman (rank) correlation between the pairwise distances of the embeddings from different iterations of the same experimental configuration.<br>\n",
    "<br>\n",
    "_Why use the Spearman correlation?_<br>\n",
    "- _Cosine Similarity_: We don't care about the angle between embeddings, just that we maintain their distances relative to each other. We should allow for scaling and rotation of the embeddings, which would change the cosine similarity but not the relative distances between points.<br>\n",
    "- _Pearson Correlation_: We don't care about the exact distances between points, just that they maintain their relative distances to each other. We should allow for scaling and rotation of the embeddings, which would change the Pearson correlation but not the Spearman correlation.<br>\n",
    "- _Procrustes Analysis_: This is a more complex method that involves finding the optimal scaling and rotation to align two embeddings before calculating their similarity. This could be a good option, but it is more computationally intensive and may not be necessary for our purposes. The Spearman correlation is a simpler and more interpretable metric that still captures the stability of the embeddings across iterations.<br>"
   ],
   "id": "d76a6e0e966d6d25"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "id": "ba1c277334eb52f",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "id": "7359ee9c51ef4954",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
