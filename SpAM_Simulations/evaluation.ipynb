{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2026-02-17T03:57:53.676063200Z",
     "start_time": "2026-02-17T03:57:53.651267200Z"
    }
   },
   "source": [
    ""
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-17T03:57:55.700995500Z",
     "start_time": "2026-02-17T03:57:53.688860300Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import os\n",
    "import time\n",
    "from itertools import combinations, product\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "\n",
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots\n",
    "import plotly.express.colors as px_colors\n",
    "import plotly.io as pio\n",
    "from scipy.spatial.distance import squareform\n",
    "\n",
    "import SpAM_Simulations.metrics as metrics\n",
    "from SpAM_Simulations.experiment import ExperimentParameters\n",
    "from SpAM_Simulations.simulation import load_latest_simulation, create_simulation\n",
    "\n",
    "pio.renderers.default = 'browser'"
   ],
   "id": "db5cd83d5162a54a",
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Load or Make Simulation",
   "id": "569fe8f490f84a2d"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "start_time": "2026-02-17T03:57:55.737937100Z"
    }
   },
   "cell_type": "code",
   "source": [
    "try:\n",
    "    sim = load_latest_simulation(os.getcwd())\n",
    "except FileNotFoundError:\n",
    "\n",
    "    # # small and simple simulation\n",
    "    # sim = create_simulation(\n",
    "    #     n_images = 50,\n",
    "    #     n_dims = 10,\n",
    "    #     num_subjects = [20, 30],\n",
    "    #     trials_per_subject = [8, 10],\n",
    "    #     images_per_trial = [16, 20],\n",
    "    #\n",
    "    #     subjects_noise_scale = [0.2, 0.8],     # relative to gt_distances.std()\n",
    "    #     subjects_noise_df = [1, 5],\n",
    "    #     reps = 3,\n",
    "    #     seed = 42,\n",
    "    #     verbose = True,\n",
    "    # )\n",
    "    #\n",
    "    # # no-noise simulation\n",
    "    # sim = create_simulation(\n",
    "    #     n_images = 754,\n",
    "    #     n_dims = 10,\n",
    "    #     num_subjects = [20, 50],\n",
    "    #     trials_per_subject = [10, 15],\n",
    "    #     images_per_trial = [16, 25],\n",
    "    #\n",
    "    #     subjects_noise_scale = [0.0],     # relative to gt_distances.std()\n",
    "    #     subjects_noise_df = [5],\n",
    "    #     reps = 3,\n",
    "    #     seed = 42,\n",
    "    #     verbose = True,\n",
    "    # )\n",
    "\n",
    "    # the real, heavy simulation with all configurations\n",
    "    sim = create_simulation(\n",
    "        n_images = 754,\n",
    "        n_dims = 10,\n",
    "        num_subjects = [20, 30, 200],\n",
    "        trials_per_subject = [10, 15],\n",
    "        images_per_trial = [16, 20, 25],\n",
    "        subjects_noise_scale = [0, 0.2, 0.5, 0.8],    # relative to gt_distances.std()\n",
    "        subjects_noise_df = [1, 5],\n",
    "        reps = 3,\n",
    "        seed = 42,\n",
    "        verbose = True,\n",
    "    )"
   ],
   "id": "1565a6331b861acc",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running experiments:  25%|██▍       | 107/432 [01:03<11:21,  2.10s/it]"
     ]
    }
   ],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Evaluate Simulation\n",
    "### Coverage\n",
    "We check three coverage scores for the simulated data:\n",
    "1. **Image Coverage**: the percentage of images that were observed at least once across all subjects and trials.\n",
    "2. **Pair Coverage**: the percentage of image-pairs that were observed at least once across all subjects and trials.\n",
    "3. **P[_is connected_]**: the probability that the graph of observed image-pairs is fully connected (i.e. has only 1 connected component). We check this because the `MDS` algorithm requires a fully connected graph to run, so if we have a low probability of getting a fully connected graph for a given experimental configuration, that configuration may not be suitable for running MDS on."
   ],
   "id": "32e6ca94afcd65b1"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "coverage = []\n",
    "for param in sim._results.keys():\n",
    "    for rep, result in enumerate(sim._results[param]):\n",
    "        coverage.append(pd.Series(metrics.coverage(result)).rename((*param, rep)))\n",
    "del param, rep, result\n",
    "\n",
    "coverage = pd.concat(coverage, axis=1).T\n",
    "coverage.index.names = [\n",
    "    'n_subjects', 'trials_per_subject', 'images_per_trial', 'subjects_noise_scale', 'subjects_noise_df', 'rep',\n",
    "]\n",
    "coverage[\"is_connected\"] = coverage[\"num_connected_components\"] == 1.0\n",
    "\n",
    "# coverage scores are not affected by subject noise, so we average across those parameters\n",
    "coverage_summary = (\n",
    "    coverage.groupby([\"n_subjects\", \"trials_per_subject\", \"images_per_trial\"])\n",
    "    .agg(\n",
    "        num_reps = (\"img_coverage\", \"size\"),\n",
    "        percent_img_coverage_mean = (\"img_coverage\", \"mean\"),\n",
    "        percent_img_coverage_sem = (\"img_coverage\", \"sem\"),\n",
    "        percent_pair_coverage_mean = (\"pair_coverage\", \"mean\"),\n",
    "        percent_pair_coverage_sem = (\"pair_coverage\", \"sem\"),\n",
    "        p_is_connected_mean = (\"is_connected\", \"mean\"),\n",
    "        p_is_connected_sem = (\"is_connected\", \"sem\"),\n",
    "    )\n",
    "    .sort_index()\n",
    "    .reset_index()\n",
    ")"
   ],
   "id": "3bbeec254418e12",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "ROW_TITLES = {\n",
    "    \"% IMG COVERAGE\": \"percent_img_coverage\",\n",
    "    \"% PAIR COVERAGE\": \"percent_pair_coverage\",\n",
    "    \"P[CONNECTED]\": \"p_is_connected\",\n",
    "}\n",
    "COL_TITLES = {k: f\"{k} Images per Trial\" for k in coverage_summary[\"images_per_trial\"].unique()}\n",
    "coverage_fig = make_subplots(\n",
    "    rows=len(ROW_TITLES), cols=len(COL_TITLES),\n",
    "    column_titles=list(COL_TITLES.values()),\n",
    "    shared_xaxes=True, shared_yaxes=True,\n",
    "    x_title=\"Number of Subjects\",\n",
    "    vertical_spacing=0.05, horizontal_spacing=0.025,\n",
    ")\n",
    "for c, (images_per_trial, col_title) in enumerate(COL_TITLES.items()):\n",
    "    for r, (row_title, prefix) in enumerate(ROW_TITLES.items()):\n",
    "        for i, tr in enumerate(coverage_summary[\"trials_per_subject\"].unique()):\n",
    "            color = px_colors.qualitative.Plotly[i]\n",
    "            df = coverage_summary.loc[\n",
    "                (coverage_summary[\"trials_per_subject\"] == tr) & (coverage_summary[\"images_per_trial\"] == images_per_trial),\n",
    "            ]\n",
    "            coverage_fig.add_trace(\n",
    "                row=r + 1, col=c + 1, trace=go.Scatter(\n",
    "                    x=df[\"n_subjects\"],\n",
    "                    y=df[f\"{prefix}_mean\"],\n",
    "                    error_y=dict(type=\"data\", array=df[f\"{prefix}_sem\"], visible=True),\n",
    "                    name=str(tr), legendgroup=str(tr), showlegend=c == 0 and r == 0,\n",
    "                    mode=\"lines+markers\", line=dict(color=color),\n",
    "                )\n",
    "            )\n",
    "        if c == 0:\n",
    "            coverage_fig.update_yaxes(\n",
    "                row=r + 1, col=c + 1,\n",
    "                title=dict(text=row_title, font=dict(size=14, color='black'))\n",
    "            )\n",
    "del c, r, i, images_per_trial, col_title, row_title, prefix, tr, color, df\n",
    "\n",
    "coverage_fig.update_layout(\n",
    "    height=650, width=1500,\n",
    "    title=dict(\n",
    "        text=\"Coverage by Experimental Configuration\", font=dict(size=20, color='black')\n",
    "    ),\n",
    "    legend=dict(\n",
    "        title=dict(text=\"Trials per Subject\"),\n",
    "        orientation=\"h\",\n",
    "        x=1.0, xanchor=\"right\", xref=\"paper\",\n",
    "        y=1.075, yanchor=\"bottom\", yref=\"paper\",\n",
    "    ),\n",
    ")\n",
    "coverage_fig.show()"
   ],
   "id": "9f34d35492d4131e",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Stability\n",
    "We check the Spearman (rank) correlation between different iterations of the same experimental configuration to see how stable the results are."
   ],
   "id": "f8550503d991ccc3"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "correlations = dict()\n",
    "for param in sim._results.keys():\n",
    "    corrs = []\n",
    "    for res1, res2 in combinations(sim._results[param], 2):\n",
    "        try:\n",
    "            corr = metrics.spearman_correlation(res1, res2)\n",
    "            corrs.append(corr)\n",
    "        except ValueError:\n",
    "            # if we don't have mutual observations we can't compute a correlation, so we skip those cases\n",
    "            pass\n",
    "    corrs = pd.Series(corrs)\n",
    "    mean, sem = corrs.mean(), corrs.sem()\n",
    "    correlations[param] = pd.Series({\"r_mean\": mean, \"r_sem\": sem})\n",
    "del param, corrs, res1, res2, corr, mean, sem\n",
    "\n",
    "correlations = pd.DataFrame(correlations).T\n",
    "correlations.index.names = [\n",
    "    'n_subjects', 'trials_per_subject', 'images_per_trial', 'subjects_noise_scale', 'subjects_noise_df'\n",
    "]"
   ],
   "id": "ee80dbfedeb78b85",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "ROW_TITLES = {tr: f\"{tr} Trials per Subject\" for tr in coverage_summary[\"trials_per_subject\"].unique()}\n",
    "COL_TITLES = {k: f\"{k} Images per Trial\" for k in coverage_summary[\"images_per_trial\"].unique()}\n",
    "corr_fig = make_subplots(\n",
    "    rows=len(ROW_TITLES), cols=len(COL_TITLES),\n",
    "    column_titles=list(COL_TITLES.values()),\n",
    "    shared_xaxes=True, shared_yaxes=True,\n",
    "    x_title=\"Number of Subjects\",\n",
    "    vertical_spacing=0.05, horizontal_spacing=0.025,\n",
    ")\n",
    "for c, (images_per_trial, col_title) in enumerate(COL_TITLES.items()):\n",
    "    for r, (trials_per_subject, row_title) in enumerate(ROW_TITLES.items()):\n",
    "        subset = correlations.loc[\n",
    "            (correlations.index.get_level_values(\"images_per_trial\") == images_per_trial) &\n",
    "            (correlations.index.get_level_values(\"trials_per_subject\") == trials_per_subject)\n",
    "        ]\n",
    "        noise_scales = subset.index.get_level_values(\"subjects_noise_scale\").unique()\n",
    "        noise_dfs = subset.index.get_level_values(\"subjects_noise_df\").unique()\n",
    "        for i, (noise_scale, noise_df) in enumerate(product(noise_scales, noise_dfs)):\n",
    "            name = f\"Scale={noise_scale}<br>DFs={noise_df}\"\n",
    "            color = px_colors.qualitative.Plotly[i % len(px_colors.qualitative.Plotly)]\n",
    "            df = subset.loc[\n",
    "                (subset.index.get_level_values(\"subjects_noise_scale\") == noise_scale) &\n",
    "                (subset.index.get_level_values(\"subjects_noise_df\") == noise_df)\n",
    "            ]\n",
    "            corr_fig.add_trace(\n",
    "                row=r + 1, col=c + 1, trace=go.Scatter(\n",
    "                    x=df.index.get_level_values(\"n_subjects\"),\n",
    "                    y=df[\"r_mean\"],\n",
    "                    error_y=dict(type=\"data\", array=df[\"r_sem\"], visible=True),\n",
    "                    name=name, legendgroup=name, showlegend=c == 0 and r == 0,\n",
    "                    mode=\"lines+markers\", line=dict(color=color),\n",
    "                )\n",
    "            )\n",
    "        if c == 0:\n",
    "            corr_fig.update_yaxes(\n",
    "                row=r + 1, col=c + 1,\n",
    "                title=dict(text=row_title, font=dict(size=10, color='black'))\n",
    "            )\n",
    "del c, r, i, images_per_trial, col_title, trials_per_subject, row_title, noise_scale, noise_df, name, color, df\n",
    "\n",
    "corr_fig.update_layout(\n",
    "    height=650, width=1500,\n",
    "    title=dict(\n",
    "        text=\"Stability (Spearman Correlation) by Experimental Configuration\",\n",
    "        font=dict(size=20, color='black')\n",
    "    ),\n",
    "    legend=dict(\n",
    "        title=dict(text=\"Subject Noise Parameters\"),\n",
    "    ),\n",
    ")\n",
    "corr_fig.show()"
   ],
   "id": "78639d58e332551",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-07T03:39:18.786377700Z",
     "start_time": "2026-02-07T03:39:18.729349900Z"
    }
   },
   "cell_type": "markdown",
   "source": [
    "## Run MDS\n",
    "In the real world, we don't know the true dimensionality of the data (like here, `D=5 or 10`). Instead, we run the MDS algorithm on the same distance matrix with increasing target-dimensionalities (`ndim=2, 3, ..., 10`)."
   ],
   "id": "bef45a0a5fbdd90a"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import gc\n",
    "import pickle as pkl\n",
    "\n",
    "from SpAM_Simulations.multi_dimensional_scaling import run_mds"
   ],
   "id": "bfd412f34a466e5",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def mds_tasks_generator(sim_obj, max_dims):\n",
    "    \"\"\" a generator-function to iterate over experimental configurations and their simulated results \"\"\"\n",
    "    for param, results_list in sim_obj._results.items():\n",
    "        # iterate over remaining configurations' results\n",
    "        for rep_idx, res in enumerate(results_list):\n",
    "            for ndim in range(2, max_dims + 1):\n",
    "                yield param, rep_idx, res, ndim\n",
    "\n",
    "\n",
    "def load_mds_results(filepath):\n",
    "    \"\"\"\n",
    "    Loads a pickle file containing multiple appended (key, value) pairs and reconstructs them into a single dictionary.\n",
    "    \"\"\"\n",
    "    data_dict = {}\n",
    "    if not (os.path.exists(filepath) or os.path.isfile(filepath)):\n",
    "        print(f\"File {filepath} not found.\")\n",
    "        return data_dict\n",
    "    with open(filepath, \"rb\") as f:\n",
    "        count = 0\n",
    "        while True:\n",
    "            try:\n",
    "                # pickle.load reads the next object in the stream\n",
    "                key, val = pkl.load(f)\n",
    "                data_dict[key] = val\n",
    "                count += 1\n",
    "            except EOFError:\n",
    "                # End of file reached\n",
    "                break\n",
    "            except Exception as e:\n",
    "                print(f\"Corrupted record at index {count}: {e}\")\n",
    "                break\n",
    "    print(f\"Successfully loaded {count} results into dictionary.\")\n",
    "    return data_dict"
   ],
   "id": "de6a67c62e73274",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "GT_DIMS = sim.gt_embeddings.shape[1]    # number of dimensions in simulated database\n",
    "NUM_TASKS = sum(1 for _ in mds_tasks_generator(sim, GT_DIMS))\n",
    "MAX_ITERS = 500"
   ],
   "id": "ff22be99a8e0b92d",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "print(f\"Running {NUM_TASKS} MDS tasks...\")\n",
    "\n",
    "i = 0\n",
    "for exp_params, rep, exp_res, ndim in tqdm(mds_tasks_generator(sim, GT_DIMS), total=NUM_TASKS):\n",
    "    i += 1\n",
    "    try:\n",
    "        mean_dists = exp_res.distances / exp_res.num_obs    # average over bumber of observations of the image-pair\n",
    "        weights = (exp_res.num_obs > 0).astype(float)       # weight is 0 for missing image-pairs, 1 for observed\n",
    "        mds_res = run_mds(\n",
    "            dists=mean_dists,\n",
    "            weights=weights,\n",
    "            ndim=ndim,\n",
    "            max_iters=MAX_ITERS,    # relax number of iterations\n",
    "            convergence_tol=1e-6,\n",
    "            precalc_init=False,\n",
    "            verbose=False,\n",
    "        )\n",
    "        data_to_save = (mds_res[\"niter\"], mds_res[\"stress\"], mds_res[\"confdist\"].round(6).astype(np.float32))\n",
    "        del mds_res\n",
    "    except Exception as e:\n",
    "        data_to_save = e\n",
    "    key_to_save = tuple({**exp_params._asdict(), \"rep\": rep, \"ndim\": ndim}.items())\n",
    "    with open(\"mds_results.pkl\", \"ab\") as f:\n",
    "        pkl.dump((key_to_save, data_to_save), f)\n",
    "    del data_to_save, key_to_save\n",
    "    if i % 100 == 0:\n",
    "        gc.collect()"
   ],
   "id": "f293511d478a0fa6",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "mds_results = load_mds_results(\"mds_results.pkl\")",
   "id": "1ca94fe11ef83285",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Percent Failures\n",
    "We want to check the percentage of MDS runs that failed for each experimental configuration and target dimensionality.<br>\n",
    "We checked the number of connected components before, but here we check for other causes as well, for example:\n",
    "- a RuntimeError with the words \"connected component\" indicates that there were more than 1 CC.\n",
    "- a RuntimeError with the words \"max_iter\" indicates that the MDS algorithm failed to converge within the maximum number of iterations."
   ],
   "id": "c3299e75914f37a8"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from collections import Counter\n",
    "\n",
    "reasons = dict()\n",
    "for key, val in mds_results.items():\n",
    "    if isinstance(val, Exception):\n",
    "        if \"connected components\" in str(val):\n",
    "            status = \"connected components\"\n",
    "        else:\n",
    "            status = str(val)\n",
    "    elif val[0] == MAX_ITERS:\n",
    "        status = \"max_iters\"\n",
    "    else:\n",
    "        status = \"success\"\n",
    "    reasons[key] = status\n",
    "\n",
    "Counter(reasons.values())"
   ],
   "id": "ca39ee8067a7e4e8",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Scree Plot\n",
    "We plot the **Scree Plot** showing Stress vs Dimensionality, and look for the \"elbow\" in the plot to determine the optimal dimensionality.<br>\n",
    "We should see if this is stable across iterations of the same experimental configuration."
   ],
   "id": "ce5089ee368e62c2"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "success_mds_results = []\n",
    "for key, val in mds_results.items():\n",
    "    if reasons[key] != \"success\":\n",
    "        continue\n",
    "    params = {p_name: p_val for (p_name, p_val) in key}\n",
    "    mds_res = {\"n_iter\": val[0], \"stress\": val[1], \"confdist\": val[2]}\n",
    "    success_mds_results.append({**params, **mds_res})\n",
    "success_mds_results = pd.DataFrame(success_mds_results).sort_values(by=[\n",
    "    \"trials_per_subject\", \"images_per_trial\",\n",
    "    \"subjects_noise_scale\", \"subjects_noise_df\", \"num_subjects\",\n",
    "    \"rep\", \"ndim\",\n",
    "])"
   ],
   "id": "27c899f80cd705fc",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "ROW_TITLES = {tr: f\"{tr} Trials per Subject\" for tr in success_mds_results[\"trials_per_subject\"].unique()}\n",
    "COL_TITLES = {k: f\"{k} Images per Trial\" for k in success_mds_results[\"images_per_trial\"].unique()}\n",
    "stress_scree_fig = make_subplots(\n",
    "    rows=len(ROW_TITLES), cols=len(COL_TITLES),\n",
    "    column_titles=list(COL_TITLES.values()),\n",
    "    shared_xaxes=True, shared_yaxes=True,\n",
    "    x_title=\"DIMENSIONS\",\n",
    "    vertical_spacing=0.05, horizontal_spacing=0.025,\n",
    ")\n",
    "\n",
    "for c, (images_per_trial, col_title) in enumerate(sorted(COL_TITLES.items())):\n",
    "    for r, (trials_per_subject, row_title) in enumerate(sorted(ROW_TITLES.items())):\n",
    "        subset = success_mds_results.loc[\n",
    "            (success_mds_results[\"images_per_trial\"] == images_per_trial) &\n",
    "            (success_mds_results[\"trials_per_subject\"] == trials_per_subject)\n",
    "        ]\n",
    "        noise_scales = success_mds_results[\"subjects_noise_scale\"].unique()\n",
    "        noise_dfs = success_mds_results[\"subjects_noise_df\"].unique()\n",
    "        n_subjs = success_mds_results[\"num_subjects\"].unique()\n",
    "        for i, (n_subj, noise_scale, noise_df) in enumerate(product(n_subjs, noise_scales, noise_dfs)):\n",
    "            name = f\"Scale={noise_scale}<br>DFs={noise_df}<br>N={n_subj}\"\n",
    "            color = px_colors.qualitative.Plotly[i % len(px_colors.qualitative.Plotly)]\n",
    "            df = (\n",
    "                subset.loc[\n",
    "                    (success_mds_results[\"subjects_noise_scale\"] == noise_scale) &\n",
    "                    (success_mds_results[\"subjects_noise_df\"] == noise_df) &\n",
    "                    (success_mds_results[\"num_subjects\"] == n_subj)\n",
    "                ]\n",
    "                .groupby(\"ndim\")[\"stress\"]\n",
    "                .agg(N=\"count\", mean=\"mean\", sem=\"sem\",)\n",
    "            )\n",
    "            stress_scree_fig.add_trace(\n",
    "                row=r + 1, col=c + 1, trace=go.Scatter(\n",
    "                    x=df.index.get_level_values(\"ndim\"),\n",
    "                    y=df[\"mean\"],\n",
    "                    error_y=dict(type=\"data\", array=df[\"sem\"].fillna(0), visible=True),\n",
    "                    name=name, legendgroup=name, showlegend=c == len(COL_TITLES)-1 and r == len(ROW_TITLES)-1,\n",
    "                    mode=\"lines+markers\", line=dict(color=color),\n",
    "                )\n",
    "            )\n",
    "        if c == 0:\n",
    "            stress_scree_fig.update_yaxes(\n",
    "                row=r + 1, col=c + 1,\n",
    "                title=dict(text=row_title, font=dict(size=10, color='black'))\n",
    "            )\n",
    "del c, r, i, images_per_trial, col_title, trials_per_subject, row_title, noise_scale, noise_df, name, color, df\n",
    "\n",
    "stress_scree_fig.update_layout(\n",
    "    height=650, width=1500,\n",
    "    title=dict(\n",
    "        text=\"MDS Stress (lower is better)\",\n",
    "        font=dict(size=20, color='black')\n",
    "    ),\n",
    "    legend=dict(\n",
    "        title=dict(text=\"Subject Noise Parameters\"),\n",
    "    ),\n",
    ")\n",
    "stress_scree_fig.show()"
   ],
   "id": "a55751a19ceb8f93",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-07T05:54:07.010742800Z",
     "start_time": "2026-02-07T05:54:06.968469900Z"
    }
   },
   "cell_type": "markdown",
   "source": [
    "## Evaluate Embeddings\n",
    "### Stability\n",
    "We want to check how \"stable\" our embeddings are across different iterations of the same experimental configuration. To do this, we calculate the Spearman (rank) correlation between the pairwise distances of the embeddings from different iterations of the same experimental configuration.<br>\n",
    "<br>\n",
    "_Why use the Spearman correlation?_<br>\n",
    "- _Cosine Similarity_: We don't care about the angle between embeddings, just that we maintain their distances relative to each other. We should allow for scaling and rotation of the embeddings, which would change the cosine similarity but not the relative distances between points.<br>\n",
    "- _Pearson Correlation_: We don't care about the exact distances between points, just that they maintain their relative distances to each other. We should allow for scaling and rotation of the embeddings, which would change the Pearson correlation but not the Spearman correlation.<br>\n",
    "- _Procrustes Analysis_: This is a more complex method that involves finding the optimal scaling and rotation to align two embeddings before calculating their similarity. This could be a good option, but it is more computationally intensive and may not be necessary for our purposes. The Spearman correlation is a simpler and more interpretable metric that still captures the stability of the embeddings across iterations.<br>"
   ],
   "id": "d76a6e0e966d6d25"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from scipy.stats import spearmanr\n",
    "\n",
    "grouping_cols = [\n",
    "    \"trials_per_subject\", \"images_per_trial\",\n",
    "    \"subjects_noise_scale\", \"subjects_noise_df\", \"num_subjects\",\n",
    "    \"ndim\",\n",
    "]\n",
    "embedding_corrs = dict()\n",
    "for group, df in tqdm(success_mds_results.groupby(grouping_cols)[\"confdist\"]):\n",
    "    corrs = pd.Series([\n",
    "        spearmanr(res1, res2).statistic for (res1, res2) in combinations(df.values, 2)\n",
    "    ])\n",
    "    embedding_corrs[group] = {\"N\": len(corrs), \"r_mean\": corrs.mean(), \"r_sem\": corrs.sem()}\n",
    "embedding_corrs_df = pd.DataFrame(embedding_corrs).T\n",
    "embedding_corrs_df.index.names = grouping_cols\n",
    "embedding_corrs_df = embedding_corrs_df.reset_index().sort_values(by=grouping_cols)"
   ],
   "id": "2c95c8caeabb8852",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "ROW_TITLES = {tr: f\"{tr} Trials per Subject\" for tr in embedding_corrs_df[\"trials_per_subject\"].unique()}\n",
    "COL_TITLES = {k: f\"{k} Images per Trial\" for k in embedding_corrs_df[\"images_per_trial\"].unique()}\n",
    "embedded_corr_fig = make_subplots(\n",
    "    rows=len(ROW_TITLES), cols=len(COL_TITLES),\n",
    "    column_titles=list(COL_TITLES.values()),\n",
    "    shared_xaxes=True, shared_yaxes=True,\n",
    "    x_title=\"DIMENSIONS\",\n",
    "    vertical_spacing=0.05, horizontal_spacing=0.025,\n",
    ")\n",
    "for c, (images_per_trial, col_title) in enumerate(COL_TITLES.items()):\n",
    "    for r, (trials_per_subject, row_title) in enumerate(ROW_TITLES.items()):\n",
    "        subset = embedding_corrs_df.loc[\n",
    "            (embedding_corrs_df[\"images_per_trial\"] == images_per_trial) &\n",
    "            (embedding_corrs_df[\"trials_per_subject\"] == trials_per_subject)\n",
    "        ]\n",
    "        noise_scales = embedding_corrs_df[\"subjects_noise_scale\"].unique()\n",
    "        noise_dfs = embedding_corrs_df[\"subjects_noise_df\"].unique()\n",
    "        n_subjs = embedding_corrs_df[\"num_subjects\"].unique()\n",
    "        for i, (n_subj, noise_scale, noise_df) in enumerate(product(n_subjs, noise_scales, noise_dfs)):\n",
    "            name = f\"Scale={noise_scale}<br>DFs={noise_df}<br>N={n_subj}\"\n",
    "            color = px_colors.qualitative.Plotly[i % len(px_colors.qualitative.Plotly)]\n",
    "            df = subset.loc[\n",
    "                    (embedding_corrs_df[\"subjects_noise_scale\"] == noise_scale) &\n",
    "                    (embedding_corrs_df[\"subjects_noise_df\"] == noise_df) &\n",
    "                    (embedding_corrs_df[\"num_subjects\"] == n_subj)\n",
    "                ]\n",
    "            embedded_corr_fig.add_trace(\n",
    "                row=r + 1, col=c + 1, trace=go.Scatter(\n",
    "                    x=df[\"ndim\"],\n",
    "                    y=df[\"r_mean\"],\n",
    "                    error_y=dict(type=\"data\", array=df[\"r_sem\"].fillna(0), visible=True),\n",
    "                    name=name, legendgroup=name, showlegend=c == len(COL_TITLES)-1 and r == len(ROW_TITLES)-1,\n",
    "                    mode=\"lines+markers\", line=dict(color=color),\n",
    "                )\n",
    "            )\n",
    "        if c == 0:\n",
    "            embedded_corr_fig.update_yaxes(\n",
    "                row=r + 1, col=c + 1,\n",
    "                title=dict(text=row_title, font=dict(size=10, color='black'))\n",
    "            )\n",
    "del c, r, i, images_per_trial, col_title, trials_per_subject, row_title, noise_scale, noise_df, name, color,\n",
    "\n",
    "embedded_corr_fig.update_layout(\n",
    "    height=650, width=1500,\n",
    "    title=dict(\n",
    "        text=\"MDS-Stability (Spearman Correlation) by Experimental Configuration\",\n",
    "        font=dict(size=20, color='black')\n",
    "    ),\n",
    "    legend=dict(\n",
    "        title=dict(text=\"Subject Noise Parameters\"),\n",
    "    ),\n",
    ")\n",
    "embedded_corr_fig.show()"
   ],
   "id": "6ac36ec5781271c0",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "embedding_corrs_df[\"r_mean\"].describe()",
   "id": "1a1a983fad4b05f5",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "id": "7359ee9c51ef4954",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
